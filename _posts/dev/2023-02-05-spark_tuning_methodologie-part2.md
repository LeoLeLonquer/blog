---
title: "Comment optimiser Spark 2 ? Chapitre 2 : automatiser l'automatisation" 
layout: post
categories: dev spark tuning 
tags: full_post
---

Dans ce deuxi√®me article, nous allons construire un tuyau qui s'adapte automatiquement au flux de donn√©es en entr√©e.
<!--more-->

### The Problem

Dans un traitement batch, le pipeline peut recevoir des tailles de donn√©es variables. Nous pourrions simplement utiliser l'allocation dynamique Spark.  
Cependant celle-ci peut √™tre un peu overkill. Les niveaux de parall√©lisme possibles √©tant diff√©rents entre chaque jobs, notre application Spark peut rapidement
s'allouer un grand nombre d'ex√©cuteurs pour les utiliser pour une ou deux t√¢ches de courte dur√©e et √™tre inactifs le reste du temps.

Du point de vue de l'utilisation des ressources, je pr√©f√®re une allocation statique bien configur√©e. 4 ex√©cuteurs √† 4 cores utilis√©s √† 100%, sur lesquels l'on a broadcast√© ou cach√© des tables, maximise l'utilisation des ressources.  

Du point de vue du temps de traitement, une allocation dynamique est certainement un excellent outil ... jusqu'√† un certain point ! Une application faisant du yoyo entre 1 ex√©cuteur et 30 ex√©cuteurs est symptomatique d'une application mal configur√©e, qui consomme inutilement de la ressource et qui peut mettre finalement plus de temps √† s'ex√©cuter.

### The Solution 

Ma configuration id√©ale est une configuration en "scale down" avec calcul des param√®tres initiaux de la configuration en fonction des entr√©es. C'est √† dire : 
1. Pour chaque typologie de donn√©es, de traitement et de volum√©trie, nous connaissons les param√®tres optimaux `num-executors`, `executor-cores`, `executor-memory` et `spark.shuffle.partitions` (voir article [Comment optimiser Spark 2 ? Chapitre 1](spark_tuning_methodologie-part1))
2. La configuration optimale est la configuration maximale dans l'allocation dynamique (`maxExecutors = num-executors`). Pas besoin d'aller chercher des ressources inutilement, et on peut d√©sallouer si jamais on rencontre un probl√®me ("scale down").
3. Avant chaque lancement de batch, la configuration du job est calcul√©e en fonction de la volum√©trie d'entr√©e.


### Ajuster automatiquement

Pour proc√©der √† l'ajustement d'un traitement batch, nous allons :

1. s√©lectionner des volum√©tries
2. pour chacune d'entre elle :
   1. optimiser le pipeline ind√©pendamment
   2. sauvegarder les param√®tres optimis√©s dans un tableau global

Nous pourrons ensuite rechercher une r√®gle g√©n√©rale √† partir de ce tableau.  
Les principaux param√®tres √† optimiser sont les suivants :

- `num-executors` ou `maxExecutors`
- `executor-cores`
- `executor-memory`
- `spark.shuffle.partitions`


### A la recherche de la formule üß™

#### Pr√©paration de notre tableau de travail

Pr√©parer un tableau pour contenir :
- la volum√©trie en entr√©e
- les valeurs de la configuration optimale
- les m√©triques de traitement moyennes associ√©es

<div class="overflow-x-auto" markdown="1">

| Volum√©trie entr√©e | (num-executors,  executor-cores) | executor-memory | spark.shuffle.partitions | Total Uptime | Task Time | max Shuffle Spill Disk |
| ----------------- | ------------------------------------ | ----------------- | -------------------------- | ------------ | --------- | ---------------------- |
|                   |                                      |                   |                            |              |           |                        |

</div>

#### S√©lection des volum√©tries

Dans un premier temps, nous choississons le contexte d'ex√©cution le plus courant et nous y s√©lectionnons un intervalle de volum√©trie.

Exemple pour une journ√©e lambda :

- 2Go (entre 4 et 5h)
- 5Go (entre 7h et 8h)
- 10Go (entre 21h et 22h)
- 20 go (entre 12h et 13h)

Cependant, en fonction du contexte, dans une m√™me table, les donn√©es en entr√©e peuvent avoir des morphologies tr√®s diff√©rentes.
Par exemple, certains champs voient la distribution de leurs valeurs modifi√©e en fonction de la date d'ex√©cution.

Il faut donc bien conna√Ætre ses donn√©es en entr√©e et savoir que le comportement de notre pipeline peut √™tre tr√®s diff√©rent en fonction de la morphologie des donn√©es en entr√©e.

Il faudra donc
- au mieux : avoir pour chaque contexte une formule sp√©cifique
- au moins : v√©rifier que les configurations optimales du cas g√©n√©ral n'impacte pas outre mesure l'application dans un autre contexte.

#### Optimisation unitaire

Pour chacune des volum√©tries ci-dessus :
1.  Effectuer une optimisation des ressources comme d√©crit dans [Comment optimiser Spark 2 ? Chapitre 1](spark_tuning_methodologie-part1) 
2.  Noter dans notre tableau les valeurs de la configuration optimale ainsi que les m√©triques Total Uptime, Task Time.

#### Analyse des r√©sultats

En reprenant notre tableau, pour chacun des param√®tres Spark recueillis, analyser l'√©volution du param√®tre en fonction de la volum√©trie en entr√©e (observer le lien de corr√©lation, les plafonds et les plateaux ...). Au mieux faire une r√©gression.

Exemple de tableau pour (`num-executors`,  `executor-cores`)

<div class="overflow-x-auto" markdown="1">

| Volum√©trie (Go) | (num-executors,  executor-cores) |
| --------------- | ------------------------------------ |
| 2               | (10, 5)                              |
| 5               | (15, 5)                              |
| 10              | (20, 5)                              |
| 20              | (40, 5)                              |

</div>

#### Production des formules

En d√©duire des formules pour chacun des param√®tres, qui peuvent √™tre de plusieurs types :
- le param√®tre est fix√© √† une constante (ex : `executor-cores = 5` )
- le param√®tre suit une formule en fonction de la volum√©trie (ex : `num-executors = Volum√©trie*2`) 
- le param√®tre suit une formule en fonction d'autres param√®tres (ex : `spark.shuffle.partitions = num-executors * 10` )

Dans le cas d'une formule, nous pouvons fixer
- une borne inf√©rieure (si besoin)
- une borne sup√©rieure (recommand√©e)

Cela nous permet d'obtenir une expression du type : `max(borne inf√©rieure, min(borne sup√©rieure, formule))`
- Ex : `num-executors = max(10, min(100, Volum√©trie/(128Mo * 5))`

#### Mise en application des formules

Enfin, il faudra mettre en place un m√©canisme qui d√©tecte la volum√©trie en entr√©e et calcule les param√®tres Spark adapt√©s.
C'est √† vous de jouer !

## Conclusion

L'id√©e √† retenir dans cet article est de faire en sorte que son application soit **smart**.  
Vous noterez que si le traitement change en lui-m√™me, les formules seront caduques.
Cependant une fois que vous aurez l'habitude d'optimiser des pipelines, vous aurez une petite r√©f√©rence de formules √† appliquer dans diff√©rents cas d'usage qui vaudra son pesant d'or !

## Ressources

- [Facebook Tuning](https://www.slideshare.net/databricks/tuning-apache-spark-for-largescale-workloads-gaoxiang-liu-and-sital-kedia)
- [Data Mechanics Delight - better Spark UI](https://www.datamechanics.co/blog-post/building-a-better-spark-ui-data-mechanics-delight)
- [Dr. Elephant](https://www.databricks.com/fr/session/dr-elephant-for-monitoring-and-tuning-apache-spark-jobs-on-hadoop) : un ancien outil d'optimisation automatique
